{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set location of XASNet code\n",
    "import sys\n",
    "#sys.path.append('/home/samjhall/github/XASNet-XAI/src')\n",
    "sys.path.append('D:\\github\\XASNet-XAI\\src')\n",
    "# --- Standard libraries\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "# --- Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# --- PyTorch and PyG\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "# --- XASNet\n",
    "from XASNet.data import QM9_XAS\n",
    "from XASNet.data import save_split\n",
    "from XASNet.models import XASNet_GNN, XASNet_GAT, XASNet_GraphNet\n",
    "from XASNet.trainer import GNNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in the dataset\n",
    "root = './XASNet-data/mol_dataset.pt'\n",
    "go_spec = QM9_XAS(root=root,\n",
    "                  raw_dir='./XASNet-data/',\n",
    "                  spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9_XAS(319)\n",
      "------------\n",
      "Number of graphs: 319\n",
      "Number of features: 15\n",
      "\n",
      "Data(x=[30, 15], edge_index=[2, 76], edge_attr=[76, 6], spectrum=[200], idx=[1], smiles='[c:0]12[c:4]3[c:8]4[c:10]5[cH:11][cH:14][c:15]6[c:13]4[c:17]4[c:19]([cH:18][cH:16]6)[cH:20][c:22]([OH:25])[c:23]([c:21]14)[CH2:24][CH:1]1[C:2]2([CH:3]=[CH:5][C:6]32[CH:7]([CH:9]5[C:12](=[O:26])[OH:27])[O:29]2)[O:28]1')\n",
      "------------\n",
      "Number of nodes: 30\n",
      "Number of edges: 76\n",
      "Average node degree: 2.53\n",
      "Has isolated nodes: False\n",
      "Has self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# --- Print details of the dataset\n",
    "print(go_spec)\n",
    "print('------------')\n",
    "print(f'Number of graphs: {len(go_spec)}')\n",
    "print(f'Number of features: {go_spec.num_features}')\n",
    "print('')\n",
    "\n",
    "# --- Print details of the first molecule/graph in dataset\n",
    "data = go_spec[0]\n",
    "\n",
    "print(data)\n",
    "print('------------')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create spilt file with the dataset\n",
    "# --- split into test, validation and test datasets\n",
    "idxs = save_split(\n",
    "    path='./raw/xasnet-mol-split.npz',\n",
    "    ndata=len(go_spec),\n",
    "    ntrain=252,\n",
    "    nval=28,\n",
    "    ntest=39,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 252, compiled in 1 loaders\n",
      "Validation dataset length: 28, compiled in 1 loaders\n",
      "Test dataset length: 39, compiled in 1 loaders\n"
     ]
    }
   ],
   "source": [
    "# --- Create variables for each dataset split\n",
    "train_go = [go_spec[i] for i in idxs['train']]\n",
    "val_go = [go_spec[i] for i in idxs['val']]\n",
    "test_go = [go_spec[i] for i in idxs['test']]\n",
    "\n",
    "# --- Save datasets splits into dataloaders\n",
    "train_loader = DataLoader(train_go, batch_size=252, shuffle=True)\n",
    "val_loader = DataLoader(val_go, batch_size=28, shuffle=True)\n",
    "test_loader = DataLoader(test_go, batch_size=39, shuffle=False)\n",
    "\n",
    "print(f'Training dataset length: {len(train_go)}, compiled in {len(train_loader)} loaders')\n",
    "print(f'Validation dataset length: {len(val_go)}, compiled in {len(val_loader)} loaders')\n",
    "print(f'Test dataset length: {len(test_go)}, compiled in {len(test_loader)} loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataloader to a file\n",
    "torch.save(test_go, './XASNet-data/test_mol_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define cost functions\n",
    "def RSE_loss(prediction, target):\n",
    "    dE = (300 - 280) / 200\n",
    "    nom = torch.sum(dE*torch.pow((target-prediction), 2))\n",
    "    denom = torch.sum(dE*target)\n",
    "    return torch.sqrt(nom) / denom \n",
    "\n",
    "def RMSE(prediction, target):\n",
    "    return torch.sqrt(torch.mean((target - prediction)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_model'\n",
    "# --- Set number of epochs to run\n",
    "num_epochs = 500\n",
    "# --- Set the learning rate \n",
    "lr = 0.01\n",
    "# --- Milestones to reduce learning rate in steps \n",
    "milestones = np.arange(10, 100, 10).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet_GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gnn = XASNet_GNN(\n",
    "    gnn_name = 'gcn', # model type\n",
    "    in_channels = [15, 256, 128], # input nodes for each layer\n",
    "    out_channels = [256, 128, 64], # output nodes for each layer\n",
    "    num_targets = 200, # nodes for final output\n",
    "    num_layers = 3, # number of total layers\n",
    "    heads = 1\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GNN(\n",
      "  (batch_norms): ModuleList()\n",
      "  (interaction_layers): ModuleList(\n",
      "    (0): GCNConv(15, 256)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): GCNConv(256, 128)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GCNConv(128, 64)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.6, inplace=False)\n",
      "  (out): Linear(in_features=64, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cpu\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gnn)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XASNet_GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Set device for model to run on\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# --- Create the type of ML model you want to run\u001b[39;00m\n\u001b[0;32m      5\u001b[0m xasnet_gat \u001b[38;5;241m=\u001b[39m XASNet_GAT(\n\u001b[0;32m      6\u001b[0m     gat_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgatv2_custom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# model type\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     node_features_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     use_jk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gat = XASNet_GAT(\n",
    "    gat_type = 'gatv2_custom', # model type\n",
    "    node_features_dim = 15,\n",
    "    in_channels = [512, 512, 256, 128], # input nodes for each layer\n",
    "    out_channels = [512, 256, 128, 200], # output nodes for each layer\n",
    "    targets = 200, # nodes for final output\n",
    "    n_layers = 3, # number of total layers\n",
    "    n_heads = 1,\n",
    "    use_residuals = True,\n",
    "    use_jk = True\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xasnet_gat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mxasnet_gat\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xasnet_gat' is not defined"
     ]
    }
   ],
   "source": [
    "xasnet_gat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XASNet_GraphNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_graphnet = XASNet_GraphNet(\n",
    "    node_dim = 15,\n",
    "    edge_dim = 6,\n",
    "    hidden_channels = 512,\n",
    "    out_channels = 200, # output nodes for each layer\n",
    "    gat_hidd = 512,\n",
    "    gat_out = 100,\n",
    "    n_targets = 200, # nodes for final output\n",
    "    n_layers = 3 # number of total layers\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XASNet_GraphNet(\n",
       "  (graphnets): ModuleList(\n",
       "    (0): GraphNetwork(\n",
       "      (gatencoder): GATEncoder(\n",
       "        (gats): ModuleList(\n",
       "          (0): GATv2Conv(15, 512, heads=3)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): GATv2Conv(1536, 512, heads=3)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): GATv2Conv(1536, 512, heads=3)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): GATv2Conv(1536, 100, heads=1)\n",
       "        )\n",
       "      )\n",
       "      (node_model): NodeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=127, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (edge_model): EdgeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=506, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (global_model): GlobalModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=500, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-2): 2 x GraphNetwork(\n",
       "      (gatencoder): GATEncoder(\n",
       "        (gats): ModuleList(\n",
       "          (0): GATv2Conv(15, 512, heads=3)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): GATv2Conv(1536, 512, heads=3)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): GATv2Conv(1536, 512, heads=3)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): GATv2Conv(1536, 100, heads=1)\n",
       "        )\n",
       "      )\n",
       "      (node_model): NodeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (edge_model): EdgeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (global_model): GlobalModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (output_dense): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xasnet_graphnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = xasnet_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set additional ML parameters\n",
    "optimizer = torch.optim.AdamW(chosen_model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "loss_fn2 = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                 milestones=milestones,\n",
    "                                                 gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create trainier\n",
    "trainer = GNNTrainer(model = chosen_model,\n",
    "                     model_name = model_name,\n",
    "                     device = device,\n",
    "                     metric_path = './metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]c:\\Users\\a3782\\AppData\\Local\\anaconda3\\envs\\xasnet-xai\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:432: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  0%|          | 1/500 [00:00<02:06,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 | average train loss = 0.00243  and average validation loss = 0.01873  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/500 [00:05<01:33,  5.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 | average train loss = 0.00065  and average validation loss = 0.00439  |learning rate = 0.00640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 52/500 [00:10<01:29,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 | average train loss = 0.00055  and average validation loss = 0.00396  |learning rate = 0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [00:15<01:22,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 | average train loss = 0.00053  and average validation loss = 0.00410  |learning rate = 0.00210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [00:20<01:21,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 | average train loss = 0.00052  and average validation loss = 0.00393  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 127/500 [00:25<01:13,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 125 | average train loss = 0.00049  and average validation loss = 0.00404  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 152/500 [00:31<01:09,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 150 | average train loss = 0.00048  and average validation loss = 0.00402  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 177/500 [00:36<01:01,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 175 | average train loss = 0.00049  and average validation loss = 0.00394  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [00:41<01:06,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 200 | average train loss = 0.00049  and average validation loss = 0.00381  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 226/500 [00:45<00:55,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 225 | average train loss = 0.00046  and average validation loss = 0.00383  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 252/500 [00:50<00:46,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 250 | average train loss = 0.00045  and average validation loss = 0.00372  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 277/500 [00:55<00:42,  5.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 275 | average train loss = 0.00045  and average validation loss = 0.00367  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 302/500 [01:00<00:39,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300 | average train loss = 0.00046  and average validation loss = 0.00360  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 327/500 [01:05<00:33,  5.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 325 | average train loss = 0.00044  and average validation loss = 0.00359  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 352/500 [01:10<00:27,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 350 | average train loss = 0.00044  and average validation loss = 0.00356  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 377/500 [01:15<00:23,  5.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 375 | average train loss = 0.00043  and average validation loss = 0.00357  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 401/500 [01:20<00:19,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 400 | average train loss = 0.00044  and average validation loss = 0.00351  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 427/500 [01:25<00:14,  5.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 425 | average train loss = 0.00042  and average validation loss = 0.00343  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 451/500 [01:30<00:09,  4.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 450 | average train loss = 0.00041  and average validation loss = 0.00348  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 476/500 [01:35<00:04,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 475 | average train loss = 0.00042  and average validation loss = 0.00342  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:40<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ML model\n",
    "trainer.train_val(train_loader, val_loader, optimizer, RMSE,\n",
    "                  scheduler, num_epochs, write_every=25, train_graphnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    image = imageio.v2.imread(f'./images/training/graph_{t}.png')\n",
    "    frames.append(image)\n",
    "\n",
    "imageio.mimsave('./example.gif', frames, fps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/train_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/train_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./metrics/train_metrics.csv')\n",
    "ax1 = df.plot.line(x='epoch', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
