{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set location of XASNet code\n",
    "import sys\n",
    "sys.path.append('/home/samjhall/github/XASNet-XAI/src')\n",
    "#sys.path.append('D:\\github\\XASNet-XAI\\src')\n",
    "# --- Standard libraries\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "# --- Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "# --- PyTorch and PyG\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader\n",
    "# --- XASNet\n",
    "from XASNet.data import QM9_XAS\n",
    "from XASNet.data import save_split\n",
    "from XASNet.models import XASNet_GNN, XASNet_GAT, XASNet_GraphNet\n",
    "from XASNet.trainer import GNNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load in the dataset\n",
    "root = './XASNet-data/atom_dataset.pt'\n",
    "go_spec = QM9_XAS(root=root,\n",
    "                  raw_dir='./XASNet-data/',\n",
    "                  spectra=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QM9_XAS(7946)\n",
      "------------\n",
      "Number of graphs: 7946\n",
      "Number of features: 15\n",
      "\n",
      "Data(x=[32, 15], edge_index=[2, 78], edge_attr=[78, 6], spectrum=[200], vector=[15], idx=[1], smiles='[c:0]12[c:4]3[c:8]4[c:10]5[c:11]([CH:25]=[O:29])[cH:13][c:14]6[c:12]4[c:17]4[c:19]([c:18]([CH:26]=[O:31])[c:15]6[OH:16])=[CH:20][CH:22]6[C:23]([c:21]14)([CH:24]=[CH:1][C:2]2=[CH:3][CH2:5][C:6]3([CH:27]=[O:30])[CH:7]=[CH:9]5)[O:28]6', atom_num=[1], neighbors=[3])\n",
      "------------\n",
      "Number of nodes: 32\n",
      "Number of edges: 78\n",
      "Average node degree: 2.44\n",
      "Has isolated nodes: False\n",
      "Has self loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "# --- Print details of the dataset\n",
    "print(go_spec)\n",
    "print('------------')\n",
    "print(f'Number of graphs: {len(go_spec)}')\n",
    "print(f'Number of features: {go_spec.num_features}')\n",
    "print('')\n",
    "\n",
    "# --- Print details of the first molecule/graph in dataset\n",
    "data = go_spec[0]\n",
    "\n",
    "print(data)\n",
    "print('------------')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create spilt file with the dataset\n",
    "# --- split into test, validation and test datasets\n",
    "idxs = save_split(\n",
    "    path='./raw/xasnet-atom-split.npz',\n",
    "    ndata=len(go_spec),\n",
    "    ntrain=5957,\n",
    "    nval=1193,\n",
    "    ntest=796,\n",
    "    save_split=True,\n",
    "    shuffle=True, \n",
    "    print_nsample=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 5957, compiled in 47 loaders\n",
      "Validation dataset length: 1193, compiled in 19 loaders\n",
      "Test dataset length: 796, compiled in 13 loaders\n"
     ]
    }
   ],
   "source": [
    "# --- Create variables for each dataset split\n",
    "train_go = [go_spec[i] for i in idxs['train']]\n",
    "val_go = [go_spec[i] for i in idxs['val']]\n",
    "test_go = [go_spec[i] for i in idxs['test']]\n",
    "\n",
    "# --- Save datasets splits into dataloaders\n",
    "train_loader = DataLoader(train_go, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_go, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_go, batch_size=64, shuffle=False)\n",
    "\n",
    "print(f'Training dataset length: {len(train_go)}, compiled in {len(train_loader)} loaders')\n",
    "print(f'Validation dataset length: {len(val_go)}, compiled in {len(val_loader)} loaders')\n",
    "print(f'Test dataset length: {len(test_go)}, compiled in {len(test_loader)} loaders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save the dataloader to a file\n",
    "torch.save(test_go, './XASNet-data/test_atom_dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define cost functions\n",
    "def RSE_loss(prediction, target):\n",
    "    dE = (300 - 280) / 200\n",
    "    nom = torch.sum(dE*torch.pow((target-prediction), 2))\n",
    "    denom = torch.sum(dE*target)\n",
    "    return torch.sqrt(nom) / denom \n",
    "\n",
    "def RMSE(prediction, target):\n",
    "    return torch.sqrt(torch.mean((target - prediction)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set name for ML model\n",
    "model_name = 'xasnet_model'\n",
    "# --- Set number of epochs to run\n",
    "num_epochs = 300\n",
    "# --- Set the learning rate \n",
    "lr = 0.01\n",
    "# --- Milestones to reduce learning rate in steps \n",
    "milestones = np.arange(10, 100, 10).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XASNet_GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gnn = XASNet_GNN(\n",
    "    gnn_name = 'gcn', # model type\n",
    "    in_channels = [15, 512, 512, 256], # input nodes for each layer\n",
    "    out_channels = [512, 512, 256, 256], # output nodes for each layer\n",
    "    num_targets = 200, # nodes for final output\n",
    "    num_layers = 4, # number of total layers\n",
    "    heads = 1\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XASNet_GNN(\n",
      "  (interaction_layers): ModuleList(\n",
      "    (0): GCNConv(15, 512)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): GCNConv(512, 512)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): GCNConv(512, 256)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): GCNConv(256, 256)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (out): Linear(in_features=256, out_features=200, bias=True)\n",
      ")\n",
      "----\n",
      " Model will be trained on: cuda\n"
     ]
    }
   ],
   "source": [
    "# --- View the details of the created model\n",
    "print(xasnet_gnn)\n",
    "print('----')\n",
    "print(f' Model will be trained on: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XASNet_GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# --- Set device for model to run on\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# --- Create the type of ML model you want to run\u001b[39;00m\n\u001b[0;32m      5\u001b[0m xasnet_gat \u001b[38;5;241m=\u001b[39m XASNet_GAT(\n\u001b[0;32m      6\u001b[0m     gat_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgatv2_custom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# model type\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     node_features_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     use_jk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     15\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_gat = XASNet_GAT(\n",
    "    gat_type = 'gatv2_custom', # model type\n",
    "    node_features_dim = 15,\n",
    "    in_channels = [512, 512, 256, 128], # input nodes for each layer\n",
    "    out_channels = [512, 256, 128, 200], # output nodes for each layer\n",
    "    targets = 200, # nodes for final output\n",
    "    n_layers = 3, # number of total layers\n",
    "    n_heads = 1,\n",
    "    use_residuals = True,\n",
    "    use_jk = True\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xasnet_gat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mxasnet_gat\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xasnet_gat' is not defined"
     ]
    }
   ],
   "source": [
    "xasnet_gat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XASNet_GraphNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is not loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Set device for model to run on\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Create the type of ML model you want to run\n",
    "xasnet_graphnet = XASNet_GraphNet(\n",
    "    node_dim = 15,\n",
    "    edge_dim = 6,\n",
    "    hidden_channels = 512,\n",
    "    out_channels = 200, # output nodes for each layer\n",
    "    gat_hidd = 512,\n",
    "    gat_out = 100,\n",
    "    n_targets = 200, # nodes for final output\n",
    "    n_layers = 3 # number of total layers\n",
    ").to(device)\n",
    "\n",
    "# --- Location to save model\n",
    "path_to_model = osp.join('./best_model,', model_name)\n",
    "\n",
    "# --- Check if there is an already existing model\n",
    "if osp.exists(path_to_model):\n",
    "    xasnet_gnn.load_state_dict(torch.load(path_to_model))\n",
    "else:\n",
    "    print('Model is not loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XASNet_GraphNet(\n",
       "  (graphnets): ModuleList(\n",
       "    (0): GraphNetwork(\n",
       "      (gatencoder): GATEncoder(\n",
       "        (gats): ModuleList(\n",
       "          (0): GATv2Conv(15, 512, heads=3)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): GATv2Conv(1536, 512, heads=3)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): GATv2Conv(1536, 512, heads=3)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): GATv2Conv(1536, 100, heads=1)\n",
       "        )\n",
       "      )\n",
       "      (node_model): NodeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=127, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (edge_model): EdgeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=506, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (global_model): GlobalModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=500, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1-2): 2 x GraphNetwork(\n",
       "      (gatencoder): GATEncoder(\n",
       "        (gats): ModuleList(\n",
       "          (0): GATv2Conv(15, 512, heads=3)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): GATv2Conv(1536, 512, heads=3)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): GATv2Conv(1536, 512, heads=3)\n",
       "          (5): ReLU(inplace=True)\n",
       "          (6): GATv2Conv(1536, 100, heads=1)\n",
       "        )\n",
       "      )\n",
       "      (node_model): NodeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (edge_model): EdgeModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=800, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (global_model): GlobalModel(\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=600, out_features=512, bias=True)\n",
       "          (1): ReLU(inplace=True)\n",
       "          (2): Linear(in_features=512, out_features=200, bias=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (output_dense): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xasnet_graphnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_model = xasnet_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set additional ML parameters\n",
    "optimizer = torch.optim.AdamW(chosen_model.parameters(), lr=lr)\n",
    "loss_fn = torch.nn.L1Loss()\n",
    "loss_fn2 = torch.nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                 milestones=milestones,\n",
    "                                                 gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Create trainier\n",
    "trainer = GNNTrainer(model = chosen_model,\n",
    "                     model_name = model_name,\n",
    "                     device = device,\n",
    "                     metric_path = './metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]/home/samjhall/anaconda3/envs/xasnet-xai/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:432: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "  0%|          | 1/300 [00:00<04:03,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.01 mins mins\n",
      "epoch 0 | average train loss = 0.00182  and average validation loss = 0.00326  |learning rate = 0.01000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 26/300 [00:11<01:57,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.19 mins mins\n",
      "epoch 25 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 51/300 [00:22<01:46,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.37 mins mins\n",
      "epoch 50 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 76/300 [00:33<01:48,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.56 mins mins\n",
      "epoch 75 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 101/300 [00:45<01:34,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.76 mins mins\n",
      "epoch 100 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 126/300 [00:56<01:20,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 0.95 mins mins\n",
      "epoch 125 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 151/300 [01:07<01:02,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1.13 mins mins\n",
      "epoch 150 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 176/300 [01:18<00:52,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1.31 mins mins\n",
      "epoch 175 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 201/300 [01:29<00:41,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1.49 mins mins\n",
      "epoch 200 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 226/300 [01:39<00:31,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1.66 mins mins\n",
      "epoch 225 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 251/300 [01:50<00:20,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 1.85 mins mins\n",
      "epoch 250 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 276/300 [02:01<00:10,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time = 2.02 mins mins\n",
      "epoch 275 | average train loss = 0.00161  and average validation loss = 0.00326  |learning rate = 0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [02:11<00:00,  2.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- Train the ML model\n",
    "trainer.train_val(train_loader, val_loader, optimizer, RMSE,\n",
    "                  scheduler, num_epochs, write_every=25, train_graphnet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    image = imageio.v2.imread(f'./images/training/graph_{t}.png')\n",
    "    frames.append(image)\n",
    "\n",
    "imageio.mimsave('./example.gif', frames, fps=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/train_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./metrics/train_metrics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./metrics/train_metrics.csv')\n",
    "ax1 = df.plot.line(x='epoch', y='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
